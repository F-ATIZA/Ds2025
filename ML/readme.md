ğŸ“ Compte Rendu â€” Descriptif de la Base de DonnÃ©es Wine Quality (White)
ğŸ“Œ 1. Introduction

La base de donnÃ©es Wine Quality provient du UCI Machine Learning Repository.
Elle contient des informations sur des vins blancs portugais, dÃ©crits par des mesures physico-chimiques ainsi quâ€™un score de qualitÃ© attribuÃ© par des experts.

Elle est couramment utilisÃ©e pour des tÃ¢ches de rÃ©gression ou classification, notamment lâ€™apprentissage dâ€™un modÃ¨le permettant de prÃ©dire la qualitÃ© du vin.

ğŸ“¦ 2. Chargement du Dataset
from ucimlrepo import fetch_ucirepo

wine_quality = fetch_ucirepo(id=186)

X = wine_quality.data.features
y = wine_quality.data.targets

print(wine_quality.metadata)
print(wine_quality.variables)

ğŸ“Š 3. Description GÃ©nÃ©rale

Nombre total dâ€™observations : 4 898 vins blancs

Nombre de variables explicatives : 11

Variable cible : quality (score de 0 Ã  10)

Ces donnÃ©es dÃ©crivent les propriÃ©tÃ©s physico-chimiques du vin et son apprÃ©ciation par des dÃ©gustateurs.

ğŸ§ª 4. Les Variables (Features)
Variable	Description
fixed acidity	Acide fixe (g/dmÂ³)
volatile acidity	Acide volatil (g/dmÂ³)
citric acid	Acide citrique (g/dmÂ³)
residual sugar	Sucre rÃ©siduel (g/dmÂ³)
chlorides	Chlorures (g/dmÂ³)
free sulfur dioxide	SOâ‚‚ libre (mg/dmÂ³)
total sulfur dioxide	SOâ‚‚ total (mg/dmÂ³)
density	DensitÃ© (g/cmÂ³)
pH	AciditÃ© du vin
sulphates	Sulfates (g/dmÂ³)
alcohol	Teneur en alcool (%)
quality (cible)	Score de qualitÃ© (0 Ã  10)
ğŸ¯ 5. Transformation de la Variable Cible

Pour former un problÃ¨me de classification binaire, la qualitÃ© est regroupÃ©e :

Y = [0 if val <= 5 else 1 for val in y["quality"]]


0 = vin de mauvaise qualitÃ©

1 = vin de bonne qualitÃ©

Cette transformation est standard dans les Ã©tudes utilisant ce dataset.

ğŸ“ˆ 6. Analyse Statistique et Visualisations
ğŸ”¹ 6.1 Boxplots

Ils rÃ©vÃ¨lent :

de fortes diffÃ©rences dâ€™Ã©chelles entre variables,

la prÃ©sence possible de valeurs extrÃªmes,

des distributions trÃ¨s asymÃ©triques (ex : residual sugar).

ğŸ”¹ 6.2 Matrice de CorrÃ©lation

Les corrÃ©lations les plus fortes observÃ©es sont :

density â†— residual sugar

free sulfur dioxide â†— total sulfur dioxide

alcohol â†˜ density

Ces observations justifient :

lâ€™utilisation dâ€™une normalisation avant classification,

une attention particuliÃ¨re lors de la sÃ©lection des modÃ¨les sensibles aux distances.

âš™ 7. PrÃ©paration des DonnÃ©es
âœ” SÃ©paration en trois ensembles
from sklearn.model_selection import train_test_split

Xa, Xt, Ya, Yt = train_test_split(X, Y, test_size=1/3, stratify=Y)
Xa, Xv, Ya, Yv = train_test_split(Xa, Ya, test_size=0.5, stratify=Ya)


Train (Da) : apprentissage

Validation (Dv) : choix des hyperparamÃ¨tres

Test (Dt) : mesure finale

La stratification garantit la mÃªme proportion de classes dans chaque ensemble.

âœ” Normalisation
from sklearn.preprocessing import StandardScaler

sc = StandardScaler().fit(Xa)
Xa_n = sc.transform(Xa)
Xv_n = sc.transform(Xv)


Objectifs :

annuler l'effet des diffÃ©rences dâ€™Ã©chelle,

amÃ©liorer la performance des modÃ¨les basÃ©s sur la distance (k-NN).

ğŸ§  8. ModÃ¨le de Classification : k-Nearest Neighbors (k-NN)
Ã‰tapes rÃ©alisÃ©es :

Test du k-NN pour k = 3

Calcul de lâ€™erreur sur le validation set

Recherche du k optimal via un balayage de k âˆˆ [1, 40]

Cette approche permet :

dâ€™observer les phÃ©nomÃ¨nes de surapprentissage pour les petits k,

dâ€™identifier la zone oÃ¹ le modÃ¨le gÃ©nÃ©ralise le mieux.

Choix du meilleur k
err_min, idx_opt = error_val.min(), error_val.argmin()
k_star = k_vector[idx_opt]

ğŸ§¾ 9. Conclusion

La base de donnÃ©es Wine Quality (White) :

est complÃ¨te, propre et bien structurÃ©e ;

permet des analyses statistiques riches ;

met en Ã©vidence lâ€™importance de la normalisation ;

constitue un excellent support pÃ©dagogique pour :

la classification supervisÃ©e,

lâ€™analyse exploratoire,

la validation croisÃ©e,

la sÃ©lection dâ€™hyperparamÃ¨tres.

Elle reprÃ©sente un cas dâ€™Ã©tude idÃ©al pour lâ€™apprentissage du modÃ¨le k-NN et des techniques de prÃ©traitement.
